spring.application.name=SpringAI_03_1

server.port=8050

#기본 챗 모델 공급자 ollama 로 설정
spring.ai.model.chat=ollama
#ollama 서버의 앤드 포인트 
spring.ai.ollama.base-url=http://localhost:11434

#사용할 로콜 모델의 이름
spring.ai.ollama.chat.options.model=gemma2:2b
#0.0 결정적 ... 1.0 랜턴
spring.ai.ollama.chat.options.temperature=0.7

#모델이 없을 때만 자동으로 다운로드 (pull)
spring.ai.ollama.init.pull-model-strategy=when-missing
#모델 초기화 시 최대 대기 시간
spring.ai.ollama.init.timeout=60s
#실패시 재시도 횟수 
spring.ai.ollama.init.max-retries=1